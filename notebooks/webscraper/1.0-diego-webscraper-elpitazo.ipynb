{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unidecode\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import swifter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-rehabilitation",
   "metadata": {},
   "source": [
    "# Reading data and normalizing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../../data/raw/ovsp_bdd_octubre.xlsx\")\n",
    "column_names_normalized = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df.columns = column_names_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-interest",
   "metadata": {},
   "source": [
    "# Quick and Dirty EDA: Confirming that I'm subsetting the correct number of elpitazo news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confirming that I'm subsetting the correct number of elpitazo links\n",
    "    # Result: 2483 el pitazo links\n",
    "pitazo_mask = df.link_de_la_noticia.str.contains(\"https://elpitazo.net\",na=False)\n",
    "df_elpitazo = df[pitazo_mask]\n",
    "# df.link_de_la_noticia[pitazo_mask].str.split(\"/\", expand = True)[2].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-victory",
   "metadata": {},
   "source": [
    "# Elpitazo webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-senior",
   "metadata": {},
   "source": [
    "Common classes from `elpitazo`:\n",
    "\n",
    "- Titlo de noticia `tdb-title-text`\n",
    "- info general de la noticia `tdb-title-text`\n",
    "- Texto completo de la noticia class=\"tdb-block-inner td-fix-index\"\n",
    "                            id=\"bsf_rt_marker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-michael",
   "metadata": {},
   "source": [
    "## Testing with different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different classes\n",
    "# The easiest way to extract the news content is to extract all p tags and then clean them.\n",
    "\n",
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "URL = \"https://elpitazo.net/los-llanos/vecinos-de-varias-comunidades-de-acarigua-tienen-siete-anos-sin-agua/\"\n",
    "page = requests.get(URL, headers=headers, timeout=20)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "soup.find_all(\"h1\", {\"class\": \"tdb-title-text\"}) # This snippet works well to find the news article title\n",
    "# # soup.find_all(\"div\", {\"class\": \"tdb-block-inner td-fix-index\"})\n",
    "# soup.find_all(\"p\", {\"class\": \"tdb-block-inner td-fix-index\"})\n",
    "\n",
    "ls = []\n",
    "\n",
    "tags_p = soup.find_all(\"p\")\n",
    "for tags in tags_p:\n",
    "    \n",
    "    if tags.has_attr('class') and tags['class'][0] in ['contacto-datos', 'text-white', '__cf_email__']:\n",
    "        continue\n",
    "        \n",
    "    ls.append(tags.get_text())\n",
    "\n",
    "' '.join(ls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-costs",
   "metadata": {},
   "source": [
    "### Webscraper first pass\n",
    "\n",
    "TODO: Use multiprocessing instead of pandas.apply. There are too many links to do it in a sequential fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscraper_elpitazo(url:str):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    page = requests.get(url, headers=headers, timeout=20)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    tags_p = soup.find_all(\"p\")\n",
    "\n",
    "\n",
    "    ls = [] # Temporary list\n",
    "    for tags in tags_p:\n",
    "\n",
    "        if tags.has_attr('class') and tags['class'][0] in ['contacto-datos', 'text-white', '__cf_email__']:\n",
    "            continue\n",
    "\n",
    "        ls.append(tags.get_text())\n",
    "\n",
    "    complete_news = ' '.join(ls)\n",
    "    \n",
    "    return complete_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single URL Test\n",
    "URL = \"https://elpitazo.net/los-llanos/el-gas-domestico-en-acarigua-araure-cuesta-entre-10-y-20-dolares/\"\n",
    "webscraper_elpitazo(url=URL)\n",
    "\n",
    "# pd.series text \n",
    "elpitazo_text = df_elpitazo.head().link_de_la_noticia.apply(webscraper_elpitazo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-physiology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "official-indiana",
   "metadata": {},
   "source": [
    "## Multiprocessing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel processing. \n",
    "\n",
    "# First try: Didn't work\n",
    "# def parallelize_dataframe(df, func):\n",
    "#     num_processes = mp.cpu_count()\n",
    "    \n",
    "#     df_split = np.array_split(df, num_processes)\n",
    "    \n",
    "#     with mp.Pool(num_processes) as p:\n",
    "#         df = pd.concat(p.map(func, df_split))\n",
    "#     return df\n",
    "\n",
    "# parallelize_dataframe(df_elpitazo.link_de_la_noticia.head(),webscraper_elpitazo )\n",
    "\n",
    "# Second try with swifter library: THIS WORKED, however there must be a faster solution\n",
    "elpitazo_textfull = df_elpitazo.link_de_la_noticia.swifter.apply(webscraper_elpitazo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save webscraped text\n",
    "elpitazo_textfull.to_csv(\"../../data/interim/webscraping/links_elpitazo_03132021.csv\")\n",
    "\n",
    "# Join with original df\n",
    "df_elpitazo_fulltext = df.join(elpitazo_textfull,rsuffix=\"_fulltext\", how = \"left\")\n",
    "\n",
    "# Save link noticia and full text to check the quality of the web scraper\n",
    "df_elpitazo_fulltext[[\"link_de_la_noticia\",\"link_de_la_noticia_fulltext\"]].to_csv(\"../../data/interim/webscraping/fulltext_links_elpitazo_03132021.csv\")\n",
    "\n",
    "# Remove columns that were empty (this happened because I read the data from excel)\n",
    "unnamed_cols = df_elpitazo_fulltext.columns[df_elpitazo_fulltext.columns.str.contains(\"unnamed\")]\n",
    "df_elpitazo_fulltext = df_elpitazo_fulltext.drop(unnamed_cols, axis = 1)\n",
    "df_elpitazo_fulltext.to_csv(\"../../data/processed/webscraping/ovsp_bdd_elpitazotext.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
