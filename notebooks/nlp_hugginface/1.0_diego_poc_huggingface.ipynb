{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.0_diego_huggingface_poc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssGwrtWRjojT"
      },
      "source": [
        "# Huggingface POC üöÄüöÄüöÄ\n",
        "\n",
        "\n",
        "En este POC voy a enfocarme en realizar clasificaci√≥n binaria. Para esto, voy a escoger el label con mayor frequencia de la columna `tipo_de_evento`. \n",
        "\n",
        "La clasificaci√≥n va a estar enfocada en clasificar: \n",
        "   - Denuncia Falta de Servicio (label = 1)\n",
        "   - No es Denuncia Falta de Servicio (label = 2)\n",
        "\n",
        "\n",
        "|                                        |   tipo_de_evento |\n",
        "|:---------------------------------------|-----------------:|\n",
        "| DENUNCIA FALTA DEL SERVICIO            |             1134 |\n",
        "| FALTA DE SERVICIO                      |              525 |\n",
        "| PROTESTA FALTA DEL SERVICIO            |              324 |\n",
        "| DENUNCIA SERVICIO MALA CALIDAD         |              146 |\n",
        "| DENUNCIA ALTO COSTO SERVICIO           |               96 |\n",
        "| SERVICIO MALA CALIDAD                  |               69 |\n",
        "| DENUNCIA COBRO EN DIVISAS              |               37 |\n",
        "| ALTO COSTO SERVICIO                    |               21 |\n",
        "| COBRO EN DIVISAS                       |               20 |\n",
        "| PROTESTA ALTO COSTO SERVICIO           |                6 |\n",
        "| DENUNCIA                               |                5 |\n",
        "| PROTESTA                               |                4 |\n",
        "| ENEFERMEDAD ASOCIADA                   |                3 |\n",
        "| PROTESTA COBRO EN DIVISAS              |                3 |\n",
        "| METODO ALTERNATIVO PARA COCINAR        |                2 |\n",
        "| DENUNCIA TIEMPO PARA ADQUIRIR SERVICIO |                2 |\n",
        "| ENFERMEDAD ASOCIADA                    |                1 |\n",
        "| DENUNCIA RETARDO EN LA ENTREGA         |                1 |\n",
        "| PROTESTA RETARDO EN LA ENTREGA         |                1 |\n",
        "| PROTESTA TIEMPO PARA ADQUIRIR SERVICIO |                1 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhBGzIGBFBNl"
      },
      "source": [
        "# Installing Missing Libraries & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeewDJSlCD36"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LwjjtuQCFk4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Em7-IsjFFlM"
      },
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBVDMVQD4XF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaModel, RobertaTokenizer, Trainer, TrainingArguments, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY4TAcuxEtPS"
      },
      "source": [
        "# Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZUKn08EAAr"
      },
      "source": [
        "df_elpitazo_pscdd = pd.read_csv(\"/gdrive/MyDrive/sambil/datasets/elpitazo_positivelabels_devdataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xXoLsUtGTfI"
      },
      "source": [
        "## Data Wrangling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL2Ed4h-GMYU"
      },
      "source": [
        "# print(df_elpitazo_pscdd.tipo_de_evento.value_counts().to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpas76DfHD0f"
      },
      "source": [
        "df_elpitazo_pscdd[\"label\"] = (df_elpitazo_pscdd.tipo_de_evento == \"DENUNCIA FALTA DEL SERVICIO\").astype(int)\n",
        "df_elpitazo_pscdd = df_elpitazo_pscdd.convert_dtypes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2hOHCfNERIs"
      },
      "source": [
        "df_denuncia_texto = df_elpitazo_pscdd[[\"label\",\"text\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ4XosrsHuue"
      },
      "source": [
        "# Preparing to Model ü§ì\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3btyZAJEVH1"
      },
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"mrm8488/RuPERTa-base\", num_labels=1)\n",
        "tokenizer = RobertaTokenizer.from_pretrained('mrm8488/RuPERTa-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG-hiPSpLa1l"
      },
      "source": [
        "# df_denuncia_texto.loc[:,\"id\"] = list(range(df_denuncia_texto.shape[0]))\n",
        "\n",
        "# Este paso es muy importante. TODAS las columnas deben ser de tipo String\n",
        "df_denuncia_texto = df_denuncia_texto.astype(str)\n",
        "train_df = df_denuncia_texto.sample(frac = 0.8, random_state= 212)\n",
        "eval_df = df_denuncia_texto[~df_denuncia_texto.index.isin(train_df.index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLjnAMcKFeiq"
      },
      "source": [
        "# train_texts, val_texts, train_labels, val_labels = train_test_split(df_denuncia_texto[\"text\"].to_list(), \n",
        "#                                                                     df_denuncia_texto[\"label_denuncia_falta_servicio\"].to_list(), test_size=.2)\n",
        "\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "eval_dataset = Dataset.from_pandas(eval_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ1HF016IpTA"
      },
      "source": [
        "# method to tokenize the data\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], batch['label'], padding=True, truncation=True, max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3w1i7SHhUY"
      },
      "source": [
        "# training and test data definition and set format\n",
        "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
        "eval_dataset = eval_dataset.map(tokenize, batched=True, batch_size=len(eval_dataset))\n",
        "\n",
        "train_dataset = train_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
        "eval_dataset = eval_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDue-UxLjRwQ"
      },
      "source": [
        "\n",
        "# Training Model üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZaLYk6qjp9z"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPT1Xkp8IRWH"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/gdrive/MyDrive/sambil/poc_transformers/logs',          # output directory\n",
        "    num_train_epochs=50,             # total # of training epochs\n",
        "    per_device_train_batch_size=10,  # batch size per device during training\n",
        "    per_device_eval_batch_size=10,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='/gdrive/MyDrive/sambil/poc_transformers/results',            # directory for storing logs\n",
        ")\n",
        "\n",
        "# instantiate the pytorch trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=eval_dataset,           # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcD6qMR0wMsD"
      },
      "source": [
        "Estoy Bloqueado en este paso\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "TypeError                                 Traceback (most recent call last)\n",
        "<ipython-input-26-1a10a9109f73> in <module>()\n",
        "      1 # training with custom dataset\n",
        "----> 2 trainer.train()\n",
        "\n",
        "15 frames\n",
        "/usr/local/lib/python3.7/dist-packages/datasets/formatting/torch_formatter.py in _tensorize(self, value)\n",
        "     42             default_dtype = {\"dtype\": torch.float32}\n",
        "     43 \n",
        "---> 44         return torch.tensor(value, **{**default_dtype, **self.torch_tensor_kwargs})\n",
        "     45 \n",
        "     46     def _recursive_tensorize(self, data_struct: dict):\n",
        "\n",
        "TypeError: new(): invalid data type 'numpy.str_'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7FJcvCcJKvt"
      },
      "source": [
        "# training with custom dataset\n",
        "# Estoy bloqueado en este paso\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr8S4kabjjfy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}